{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IE_663_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJY8JlsusiRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.eager import context\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "from tensorflow.python.training import optimizer\n",
        "\n",
        "\n",
        "class Lookahead(optimizer.Optimizer):\n",
        "    '''Tensorflow implementation of the lookahead wrapper.\n",
        "    Lookahead Optimizer: https://arxiv.org/abs/1907.08610\n",
        "    '''\n",
        "\n",
        "    def __init__(self, optimizer, la_steps=5, la_alpha=0.8, use_locking=False, name=\"Lookahead\"):\n",
        "        \"\"\"optimizer: inner optimizer\n",
        "        la_steps (int): number of lookahead steps\n",
        "        la_alpha (float): linear interpolation factor. 1.0 recovers the inner optimizer.\n",
        "        \"\"\"\n",
        "        super(Lookahead, self).__init__(use_locking, name)\n",
        "        self.optimizer = optimizer\n",
        "        self._la_step = 0\n",
        "        self._la_alpha = la_alpha\n",
        "        self._total_la_steps = la_steps\n",
        "\n",
        "    def _create_slots(self, var_list):\n",
        "        self.optimizer._create_slots(var_list)\n",
        "\n",
        "        self._var_list = var_list\n",
        "        first_var = min(var_list, key=lambda x: x.name)\n",
        "        self._create_non_slot_variable(initial_value=self._la_step,\n",
        "                                       name=\"la_step\",\n",
        "                                       colocate_with=first_var)\n",
        "\n",
        "        # Create slots for the cached parameters.\n",
        "        for v in var_list:\n",
        "            self._zeros_slot(v, \"cached_params\", self._name)\n",
        "\n",
        "    def _prepare(self):\n",
        "        self.optimizer._prepare()\n",
        "\n",
        "        la_alpha = self._call_if_callable(self._la_alpha)\n",
        "        total_la_steps = self._call_if_callable(self._total_la_steps)\n",
        "\n",
        "        self._la_alpha_t = ops.convert_to_tensor(la_alpha, name=\"la_alpha\")\n",
        "        self._total_la_steps_t = ops.convert_to_tensor(total_la_steps, name=\"total_la_steps\")\n",
        "\n",
        "    def _get_la_step_accumulators(self):\n",
        "        with ops.init_scope():\n",
        "            if context.executing_eagerly():\n",
        "                graph = None\n",
        "            else:\n",
        "                graph = ops.get_default_graph()\n",
        "            return self._get_non_slot_variable(\"la_step\", graph=graph)\n",
        "\n",
        "    def _apply_dense(self, grad, var):\n",
        "        return self.optimizer._apply_dense(grad, var)\n",
        "\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        return self.optimizer._resource_apply_dense(grad, var)\n",
        "\n",
        "    def _apply_sparse_shared(self, grad, var, indices, scatter_add):\n",
        "        return self.optimizer._apply_sparse_shared(grad, var, indices, scatter_add)\n",
        "\n",
        "    def _apply_sparse(self, grad, var):\n",
        "        return self.optimizer._apply_sparse(grad, var)\n",
        "\n",
        "    def _resource_scatter_add(self, x, i, v):\n",
        "        return self.optimizer._resource_scatter_add(x, i, v)\n",
        "\n",
        "    def _resource_apply_sparse(self, grad, var, indices):\n",
        "        return self.optimizer._resource_apply_sparse(grad, var, indices)\n",
        "\n",
        "    def _finish(self, update_ops, name_scope):\n",
        "        inner_finish_op = self.optimizer._finish(update_ops, name_scope)\n",
        "\n",
        "        with ops.control_dependencies([inner_finish_op, ]):\n",
        "            la_step = self._get_la_step_accumulators()\n",
        "            with ops.colocate_with(la_step):\n",
        "                def update_la_step_func():\n",
        "                    # update the la_step\n",
        "                    return control_flow_ops.group([la_step.assign(\n",
        "                        la_step + 1, use_locking=self._use_locking), ])\n",
        "\n",
        "                def pull_back_func():\n",
        "                    # update the la_step\n",
        "                    update_la_step = la_step.assign(\n",
        "                        0, use_locking=self._use_locking)\n",
        "                    # interpolate the variables\n",
        "                    interpolation = [v.assign(\n",
        "                        self.get_slot(v, \"cached_params\") + self._la_alpha_t * (v - self.get_slot(v, \"cached_params\")))\n",
        "                                     for v in self._var_list]\n",
        "\n",
        "                    # update the cached params\n",
        "                    with ops.control_dependencies(interpolation):\n",
        "                        update_cached_params = [self.get_slot(v, \"cached_params\").assign(updated_v) for v, updated_v in\n",
        "                                                zip(self._var_list, interpolation)]\n",
        "                    return control_flow_ops.group([update_la_step, ] + interpolation + update_cached_params)\n",
        "\n",
        "                # condition for when to pull back the params\n",
        "                condition = tf.greater_equal(la_step, self._total_la_steps_t)\n",
        "                update_lookahead_states = tf.cond(condition,\n",
        "                                                  pull_back_func,\n",
        "                                                  update_la_step_func,\n",
        "                                                  )\n",
        "\n",
        "        return control_flow_ops.group([inner_finish_op, update_lookahead_states],\n",
        "                                      name=name_scope)\n",
        "\n",
        "    def _call_if_callable(self, param):\n",
        "        \"\"\"Call the function if param is callable.\"\"\"\n",
        "        return param() if callable(param) else param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKWoLUXVsqw2",
        "colab_type": "code",
        "outputId": "1f6ff209-d0b3-4dbf-ef52-9fa9de93ff05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import numpy as np\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-hI1O4duw-J",
        "colab_type": "code",
        "outputId": "cd5ca706-b3d5-4146-f167-09dfa92ed37a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRMGAL56vazO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(256))\n",
        "  model.add(tf.keras.layers.Activation('elu'))\n",
        "  model.add(tf.keras.layers.Dense(10))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW9dWtFE1THt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = create_model()\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(1e-3)\n",
        "\n",
        "model1.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUC-byDZusp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = create_model()\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(1e-3)\n",
        "\n",
        "model2.compile(\n",
        "    optimizer=Lookahead(optimizer, la_steps=5, la_alpha=0.8),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0r_c5otWEjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = create_model()\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(1e-3)\n",
        "\n",
        "model3.compile(\n",
        "    optimizer=Lookahead(optimizer, la_steps=10, la_alpha=0.8),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex0z2m4yWVaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4 = create_model()\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(1e-3)\n",
        "\n",
        "model4.compile(\n",
        "    optimizer=Lookahead(optimizer, la_steps=20, la_alpha=0.8),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI-QXkRGWcyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model5 = create_model()\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(1e-3)\n",
        "\n",
        "model5.compile(\n",
        "    optimizer=Lookahead(optimizer, la_steps=5, la_alpha=0.6),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aebvUVH_WjMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model6 = create_model()\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(1e-3)\n",
        "\n",
        "model6.compile(\n",
        "    optimizer=Lookahead(optimizer, la_steps=10, la_alpha=0.6),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KjtGGG7zItA",
        "colab_type": "code",
        "outputId": "1a53bfea-ca48-4114-d06c-cedd7ba19521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "history1 = model1.fit(\n",
        "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=600,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    validation_freq=17\n",
        ")\n",
        "\n",
        "print(history1.history)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 18s 30ms/step - loss: 1.0905 - sparse_categorical_accuracy: 0.8216\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 18s 30ms/step - loss: 0.2837 - sparse_categorical_accuracy: 0.8956\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 18s 30ms/step - loss: 0.2431 - sparse_categorical_accuracy: 0.9110\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 18s 30ms/step - loss: 0.2138 - sparse_categorical_accuracy: 0.9203\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 18s 30ms/step - loss: 0.1957 - sparse_categorical_accuracy: 0.9274\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 18s 30ms/step - loss: 0.1860 - sparse_categorical_accuracy: 0.9309\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 18s 30ms/step - loss: 0.1723 - sparse_categorical_accuracy: 0.9353\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 18s 30ms/step - loss: 0.1654 - sparse_categorical_accuracy: 0.9373\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 18s 30ms/step - loss: 0.1562 - sparse_categorical_accuracy: 0.9413\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 18s 30ms/step - loss: 0.1562 - sparse_categorical_accuracy: 0.9420\n",
            "{'loss': [1.0904664993286133, 0.2836657464504242, 0.24310573935508728, 0.21381902694702148, 0.19565501809120178, 0.18596601486206055, 0.1722569763660431, 0.16535115242004395, 0.15617439150810242, 0.15621936321258545], 'sparse_categorical_accuracy': [0.821566641330719, 0.895633339881897, 0.9109500050544739, 0.9203333258628845, 0.9273999929428101, 0.930899977684021, 0.9352999925613403, 0.9373499751091003, 0.9412999749183655, 0.9419500231742859]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkxNvbxsBJIj",
        "colab_type": "code",
        "outputId": "604caa6f-6117-4306-fc2e-dfeb52922780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "history2 = model2.fit(\n",
        "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=600,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    validation_freq=17\n",
        ")\n",
        "\n",
        "print(history2.history)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.8969 - sparse_categorical_accuracy: 0.8300\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2631 - sparse_categorical_accuracy: 0.9029\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2265 - sparse_categorical_accuracy: 0.9158\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1967 - sparse_categorical_accuracy: 0.9264\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1787 - sparse_categorical_accuracy: 0.9329\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1626 - sparse_categorical_accuracy: 0.9397\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1554 - sparse_categorical_accuracy: 0.9412\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1424 - sparse_categorical_accuracy: 0.9459\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1276 - sparse_categorical_accuracy: 0.9512\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1263 - sparse_categorical_accuracy: 0.9528\n",
            "{'loss': [0.8968866467475891, 0.26313987374305725, 0.22648416459560394, 0.19670893251895905, 0.17874263226985931, 0.162642240524292, 0.1553630530834198, 0.14239048957824707, 0.12760722637176514, 0.1262667030096054], 'sparse_categorical_accuracy': [0.8300166726112366, 0.9029333591461182, 0.9158333539962769, 0.9264166951179504, 0.9328666925430298, 0.9396666884422302, 0.94118332862854, 0.9459166526794434, 0.9512333273887634, 0.9528499841690063]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebGyNJPOZsnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "21c56853-e9a0-4f01-fc43-788857c041f1"
      },
      "source": [
        "history3 = model3.fit(\n",
        "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=600,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    validation_freq=17\n",
        ")\n",
        "\n",
        "print(history3.history)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.9582 - sparse_categorical_accuracy: 0.8274\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2710 - sparse_categorical_accuracy: 0.9005\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2285 - sparse_categorical_accuracy: 0.9139\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1993 - sparse_categorical_accuracy: 0.9250\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1825 - sparse_categorical_accuracy: 0.9319\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1678 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1513 - sparse_categorical_accuracy: 0.9435\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1452 - sparse_categorical_accuracy: 0.9459\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1411 - sparse_categorical_accuracy: 0.9481\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9532\n",
            "{'loss': [0.958195686340332, 0.2710147500038147, 0.228478342294693, 0.19928444921970367, 0.18250231444835663, 0.1677701622247696, 0.15127858519554138, 0.14517052471637726, 0.14106224477291107, 0.12215832620859146], 'sparse_categorical_accuracy': [0.8274000287055969, 0.9004999995231628, 0.9138666391372681, 0.9250166416168213, 0.9319166541099548, 0.9374666810035706, 0.9434999823570251, 0.9458833336830139, 0.9480833411216736, 0.9531833529472351]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G68oOiPZyid",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "8e4e7030-c3c2-4d58-ad77-7fae1db63e67"
      },
      "source": [
        "history4 = model4.fit(\n",
        "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=600,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    validation_freq=17\n",
        ")\n",
        "\n",
        "print(history4.history)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 1.0630 - sparse_categorical_accuracy: 0.8173\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2782 - sparse_categorical_accuracy: 0.8956\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2357 - sparse_categorical_accuracy: 0.9120\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2100 - sparse_categorical_accuracy: 0.9204\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1901 - sparse_categorical_accuracy: 0.9288\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1704 - sparse_categorical_accuracy: 0.9361\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1604 - sparse_categorical_accuracy: 0.9398\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1515 - sparse_categorical_accuracy: 0.9437\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1373 - sparse_categorical_accuracy: 0.9483\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1343 - sparse_categorical_accuracy: 0.9496\n",
            "{'loss': [1.0629549026489258, 0.27821293473243713, 0.23568783700466156, 0.20998528599739075, 0.1900835782289505, 0.17038510739803314, 0.1604107916355133, 0.15150566399097443, 0.13729621469974518, 0.1343255341053009], 'sparse_categorical_accuracy': [0.8172833323478699, 0.895550012588501, 0.9120000004768372, 0.920366644859314, 0.9287833571434021, 0.9361166954040527, 0.9397666454315186, 0.9436833262443542, 0.9483000040054321, 0.94964998960495]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bes9NorWZ1g1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "07a8fc12-9822-42ca-849d-6d1f3fe6ef01"
      },
      "source": [
        "history5 = model5.fit(\n",
        "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=600,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    validation_freq=17\n",
        ")\n",
        "\n",
        "print(history5.history)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.8717 - sparse_categorical_accuracy: 0.8214\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2682 - sparse_categorical_accuracy: 0.9007\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2252 - sparse_categorical_accuracy: 0.9166\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1933 - sparse_categorical_accuracy: 0.9286\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1705 - sparse_categorical_accuracy: 0.9355\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1520 - sparse_categorical_accuracy: 0.9430\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1350 - sparse_categorical_accuracy: 0.9491\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1281 - sparse_categorical_accuracy: 0.9517\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1140 - sparse_categorical_accuracy: 0.9565\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1027 - sparse_categorical_accuracy: 0.9615\n",
            "{'loss': [0.8717005848884583, 0.26819178462028503, 0.22519956529140472, 0.19333207607269287, 0.17053692042827606, 0.1519627422094345, 0.13496793806552887, 0.12807711958885193, 0.11399805545806885, 0.10266362875699997], 'sparse_categorical_accuracy': [0.8213666677474976, 0.9006500244140625, 0.9165833592414856, 0.9285833239555359, 0.9355166554450989, 0.9430000185966492, 0.9491000175476074, 0.9517166614532471, 0.9564999938011169, 0.9615499973297119]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLI9dSb0Z6WD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "91868098-c666-49a2-b977-28ab24fdff0e"
      },
      "source": [
        "history6 = model6.fit(\n",
        "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=600,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    validation_freq=17\n",
        ")\n",
        "\n",
        "print(history6.history)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 1.0656 - sparse_categorical_accuracy: 0.8129\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2738 - sparse_categorical_accuracy: 0.8990\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.2245 - sparse_categorical_accuracy: 0.9158\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1932 - sparse_categorical_accuracy: 0.9284\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1714 - sparse_categorical_accuracy: 0.9355\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1478 - sparse_categorical_accuracy: 0.9431\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1330 - sparse_categorical_accuracy: 0.9484\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1242 - sparse_categorical_accuracy: 0.9528\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1080 - sparse_categorical_accuracy: 0.9592\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 19s 31ms/step - loss: 0.1039 - sparse_categorical_accuracy: 0.9604\n",
            "{'loss': [1.0656099319458008, 0.27384957671165466, 0.22450201213359833, 0.19315072894096375, 0.17140942811965942, 0.14778201282024384, 0.13298730552196503, 0.12418126314878464, 0.10795404016971588, 0.10386539995670319], 'sparse_categorical_accuracy': [0.8129333257675171, 0.8990499973297119, 0.9157500267028809, 0.9283833503723145, 0.9354666471481323, 0.9430666565895081, 0.9484333395957947, 0.9527833461761475, 0.9591666460037231, 0.9603666663169861]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHQj3IHEiu6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('final_ans_2.txt') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYxfkbG5iRjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"final_ans_2.txt\",\"w+\") as fi:\n",
        "  fi.write(', '.join([str(num) for num in history1.history[\"loss\"]]))\n",
        "  fi.write('\\n')\n",
        "  fi.write(', '.join([str(num) for num in history2.history[\"loss\"]]))\n",
        "  fi.write('\\n')\n",
        "  fi.write(', '.join([str(num) for num in history3.history[\"loss\"]]))\n",
        "  fi.write('\\n')\n",
        "  fi.write(', '.join([str(num) for num in history4.history[\"loss\"]]))\n",
        "  fi.write('\\n')\n",
        "  fi.write(', '.join([str(num) for num in history5.history[\"loss\"]]))\n",
        "  fi.write('\\n')\n",
        "  fi.write(', '.join([str(num) for num in history6.history[\"loss\"]]))\n",
        "  fi.write('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}